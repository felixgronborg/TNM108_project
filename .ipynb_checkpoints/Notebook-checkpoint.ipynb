{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# President tweet sentiment analysis\n",
    "\n",
    "We are going to show you how to download, process and analyse the sentiment of real tweets. \n",
    "We have chosen to download tweets from the two last presidents of USA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweepy and Twitter API\n",
    "First you need to setup your libraries and your API\n",
    "We have chosen to use the python library Tweepy for downloading tweets and managing our Twitter API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import API\n",
    "from tweepy import OAuthHandler\n",
    "import twitter_credentials\n",
    "\n",
    "auth = OAuthHandler(twitter_credentials.CONSUMER_KEY, twitter_credentials.CONSUMER_SECRET)\n",
    "auth.set_access_token(twitter_credentials.ACCESS_TOKEN, twitter_credentials.ACCESS_TOKEN_SECRET)\n",
    "twitter_client = API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Tweets\n",
    "Now that you have your API set up you can start downloading tweets. There are several ways to do this, but we have chosen to use Tweepy's Cursor function, because it's easy to understand and it required the least amount of code.\n",
    "We will start by downloading the tweets from Barack Obama, with the Twitter handle @BarackObama.\n",
    "Since we want to analyse the sentiment of Obamas own tweets we will exclude both manual and regular retweets.\n",
    "We have also chosen to analyse tweets from when he was president as we will do with Donald Trump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2579\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from datetime import date\n",
    "from tweepy import Cursor\n",
    "\n",
    "twitter_user = 'BarackObama'\n",
    "obama_tweets = []\n",
    "\n",
    "startDate = datetime.datetime(2009, 1, 20, 0, 0 ,0)\n",
    "endDate = datetime.datetime(2017, 1, 20, 0, 0 ,0)\n",
    "\n",
    "for tweet in Cursor(twitter_client.user_timeline, twitter_user, tweet_mode='extended').items():\n",
    "    if (not tweet.retweeted) and ('RT' not in tweet.full_text) and (tweet.created_at < endDate) and (tweet.created_at > startDate):\n",
    "        obama_tweets.append(tweet)\n",
    "\n",
    "\n",
    "print(len(obama_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now do the same for Donald Trump. Since he somehow still is the sitting president we will set the end date for his tweets as 1 Jan 2021, which has not yet happened. His Twitter handle is @realDonaldTrump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "twitter_user = 'realDonaldTrump'\n",
    "trump_tweets = []\n",
    "\n",
    "startDate = datetime.datetime(2017, 1, 20, 0, 0 ,0)\n",
    "endDate = datetime.datetime(2021, 1, 1, 0, 0 ,0)\n",
    "\n",
    "for tweet in Cursor(twitter_client.user_timeline, twitter_user, tweet_mode='extended').items():\n",
    "    if (not tweet.retweeted) and ('RT' not in tweet.full_text) and (tweet.created_at < endDate) and (tweet.created_at > startDate):\n",
    "        trump_tweets.append(tweet)\n",
    "\n",
    "\n",
    "print(len(trump_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting lists to dataframes\n",
    "To use these lists of tweets as datasets we need to convirt them. We will do this with the help of pandas DataFrame() funcion and create our own function where we can decide what information we want to save. In this case we choose to save the text of the tweet, date of the tweet, tweet ID, number of favorites and number of retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-efcf9ee88620>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtrump_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweets_to_data_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrump_tweets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mobama_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweets_to_data_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobama_tweets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-efcf9ee88620>\u001b[0m in \u001b[0;36mtweets_to_data_frame\u001b[1;34m(tweets)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_text\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweets'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreated_at\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid_str\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'retweets'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretweet_count\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def tweets_to_data_frame(tweets):\n",
    "        df = pd.DataFrame(data=[tweet.full_text for tweet in tweets], columns=['Tweets'])\n",
    "\n",
    "        df['date'] = np.array([tweet.created_at for tweet in tweets])\n",
    "        df['id'] = np.array([tweet.id_str for tweet in tweets])\n",
    "        df['retweets'] = np.array([tweet.retweet_count for tweet in tweets])\n",
    "        df['favorites'] = np.array([tweet.favorite_count for tweet in tweets])\n",
    "\n",
    "        return df\n",
    "    \n",
    "trump_df = tweets_to_data_frame(trump_tweets)\n",
    "obama_df = tweets_to_data_frame(obama_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving datasets as CSV files for later use\n",
    "We don't want to have to download tweets every time we want to run our program. Thus we can save and load our dataframes to and from CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "trump_df.to_csv('trump_tweets.csv', sep='\\t', encoding='utf-8', index=False)\n",
    "obama_df.to_csv('obama_tweets.csv', sep='\\t', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issues with this method\n",
    "As you can see we only managed to find a few tweets from Donald Trump, while we found more than 2000 from Barack Obama. We do not know why this is the case, but for some reason it's harder to download tweets from Trump. \n",
    "\n",
    "Luckily there are other methods to find tweets from Donald Trump. We have used http://www.trumptwitterarchive.com/archive to download his tweets and make a CSV file. We have also previously saved Obamas tweets to another CSV file. We will now load them both and use as our Dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-74b4911d30ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrump_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trump.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mobama_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"obama.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "trump_df = pd.read_csv(\"trump.csv\", error_bad_lines=False, sep='\\t')\n",
    "obama_df = pd.read_csv(\"obama.csv\", error_bad_lines=False, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
